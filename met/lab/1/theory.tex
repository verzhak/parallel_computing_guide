
\mysubsubsection{Введение}

В настоящее время существуют два принципиально отличных друг от друга аппаратных способа улучшения временной эффективности выполнения произвольных расчетов с помощью средств вычислительной техники.

Первый способ состоит в технологическом совершенствовании средств вычислительной техники. Этот способ, хотя и является относительно дешевым, имеет существенный недостаток - в настоящее время эволюционное развитие технологий создания отдельных узлов вычислительных систем - процессоров, оперативной памяти - подошло к своему теоретическому пределу и требуется революционный скачок, в результате которого человечество должно получить принципиально новые технологии создания перечисленных узлов вычислительных систем. Очевидно, что таковой скачок требует существенных материальных средств, и поэтому его осуществление - дело среднесрочной перспективы.

Второй способ, которому посвящен настоящий курс лабораторных работ, заключается в распределении вычислительной нагрузки между несколькими вычислительными устройствами. Данный способ требует б\'{о}льших, по сравнению с предыдущим способом, затрат на оборудование, однако позволяет практически неограниченно (учитывая, разумеется, материальные и кадровые ресурсы) наращивать вычислительные мощности, могущие быть использованными для решения целевой задачи. В этом случае можно говорить о двух способах повышения временной эффективности выполняемых вычислений:

\begin{itemize}

	\item Параллельные вычисления - выполнение различных частей алгоритма в отдельных вычислительных потоках на обособленных друг от друга вычислительных устройствах и дальнейшее мультиплексирование результатов выполнения частей алгоритма главным вычислительным потоком;

	\item Распределенные вычисления - выполнение одного и того же алгоритма в отдельных вычислительных потоках на обособленных друг от друга вычислительных устройствах на различных наборах данных. Результаты выполнения алгоритма различными вычислительными потоками объединяются и анализируются главным вычислительным потоком.

\end{itemize}

Вычислительная система, позволяющая выполнять параллельные / распределенные вычисления, состоит из нескольких вычислительных устройств, которые, в свою очередь, состоят, как минимум, из процессора и, возможно, оперативной памяти. В случае, когда вычислительная система представляет собой кластер вычислительных систем, вычислительные устройства суть есть обособленные вычислительные системы с собственным процессором, оперативной памятью, материнской платой, сетевой картой и тому подобными аппаратными средствами.

Существует несколько способов классификации параллельных систем - два наиболее популярных способа приведено ниже:

\begin{itemize}

	\item Классификация параллельных систем по Флинну.

	Майкл Флинн (Michael Flynn) в 70-е годы выделил четыре класса архитектур ЭВМ:

	\begin{itemize}
	
		\item ОКОД — вычислительные системы с одиночным потоком команд и одиночным потоком данных (SISD - Single Instruction stream over a Single Data stream);
		\item ОКМД — вычислительные системы с одиночным потоком команд и множественным потоком данных (SIMD - Single Instruction, Multiple Data);
		\item МКОД — вычислительные системы со множественным потоком команд и одиночным потоком данных (MISD - Multiple Instruction Single Data);
		\item МКМД — вычислительные системы со множественным потоком команд и множественным потоком данных (MIMD - Multiple Instruction Multiple Data);

	\end{itemize}

	\item Классификация параллельных систем по способу взаимодействия вычислительных потоков:

	\begin{itemize}

		\item Взаимодействие через разделяемую память.

			Вычислительные потоки разделяют область оперативной памяти - то есть имеют общий доступ к ней на тех или иных условиях (как правило, рассматриваются права на чтение, запись и, реже, выполнение);

		\item Взаимодействие путем обмена сообщениями.

			Более совершенный способ организации параллельных вычислений. Вычислительные потоки обмениваются сообщениями через поток - супервизор.

	\end{itemize}

\end{itemize}

Вычислительные системы, построенные на базе процессоров архитектур IA-32 (x86) и x86-64 (AMD64, IA-32e, Intel 64), относятся к классу SIMD по следующим причинам:

\begin{itemize}

	\item Одноядерные процессоры реализуют конвейерные вычисления и виртуальные многопоточные вычисления;
	\item Многоядерные процессоры также реализуют конвейеры и, кроме того, могут выполнять вычисления параллельно на нескольких ядрах, обладающих доступом к одним и тем же данным в разделяемой ими оперативной памяти.

	Вычислительные системы, построенные на многоядерных процессорах перечисленных архитектур, относятся к классу SMP-систем (Symmetric MultiProcessing; симметричная мультипроцессорность) - к классу многопроцессорных систем с общей оперативной памятью и одинаковыми характеристиками доступа к оперативной памяти вычислительными устройствами (процессорами, ядрами процессоров).

\end{itemize}

В настоящей лабораторной работе рассматривается способ организации параллельных вычислений путем запуска нескольких вычислительных потоков, взаимодействующих через разделяемую память.

\mysubsubsection{Многопоточное программирование в \gl с взаимодействием вычислительных потоков через разделяемую память}

\gl предоставляет программисту следующий инструментарий запуска и управления вычислительными потоками:

\begin{itemize}

	\item Запуск вычислительных потоков.

	Для запуска вычислительных потоков могут быть использованы следующие системные вызовы:

	\begin{itemize}

		\item fork - запускает новый процесс системы, дочерний по отношению к запускающему процессу.

		Новый процесс системы получает в свое распоряжение копию виртуального адресного пространства родительского процесса;

		\item clone - запускает новый процесс системы, дочерний по отношению к запускающему процессу.

		 Системный вызов clone позволяет родительскому процессу указать, какие части своего виртуального адресного пространства тот будет разделять со своим дочерним процессом.

		 Системный вызов clone позволяет запускать легковесные процессы (LWP - Lite-Weight Process) - процессы, разделяющие со своим родительским процессом его виртуальное адресное пространство;

	\end{itemize}

	\item Ожидание завершения вычислительных потоков.

	Для ожидания завершения процессов системы, реализующих вычислительные потоки, некоторый процесс системы может использовать следующие системные вызовы:

	\begin{itemize}

		\item wait - для ожидания завершения произвольного дочернего процесса;
		\item waitpid, wait4 - для ожидания завершения дочернего процесса, обладающего указанным идентификатором процесса (PID - Process IDentifier);

	\end{itemize}

	\item Останов вычислительных потоков.

	Для останова процессов системы, реализующих вычислительные потоки, некоторый процесс системы может отправить им сигналы SIGTERM или SIGKILL, для чего он должен использовать системный вызов kill;

	\item Организация взаимодействия вычислительных потоков через разделяемую память.

	Существует несколько способов организации взаимодействия процессов системы, реализующих вычислительные потоки, через разделяемую память:

	\begin{itemize}

		\item Запуск легковесных процессов, разделяющих с родительским его виртуальное адресное пространство;
		\item Использование функционала стандарта POSIX IPC - системные вызовы shmat, shmdt, shmget и прочие;
		\item Разделяемые отображения файлов в память, разделяемые анонимные отображения - системные вызовы mmap и munmap.

	\end{itemize}

\end{itemize}

Реализация параллельных вычислений с использованием системных вызовов \linebreak \gl является достаточно трудоемким занятием, поскольку программист берет на себя отслеживание всех ошибок, могущих появится в случае некорректного завершения того или иного системного вызова.

Очевидна необходимость использования специальных библиотек, позволяющих организовывать параллельные / распределенные вычисления. Программист, использующий данные библиотеки, получает возможность сконцентрироваться непосредственно на распараллеливании целевого алгоритма или на организации распределенных вычислений.

К числу библиотек, специализирующихся на организации параллельных вычислений, относится стандарт OpenMP.

\mysubsubsection{Стандарт OpenMP}

Стандарт OpenMP (Open Multi-Processing) представляет собой набор директив компилятора, процедур и переменных окружения, предназначенных для программирования многопоточных приложений на многопроцессорных системах с общей памятью (SMP-системах).

Первый версия стандарта OpenMP была разработана в 1997 году для языка программирования Fortran. Позже стандарт OpenMP был дополнен спецификациями для языков программирования C и C++. Спецификация стандарта OpenMP может быть бесплатно получена на сайте некоммерческой организации <<OpenMP Architecture Review Board>> \cite{openmp}, курирующей процесс доработки стандарта.

В стандарте OpenMP используется модель параллельного выполнения <<ветвление - слияние>>. Программа OpenMP начинается как единственный поток выполнения, называемый начальным потоком. Когда поток встречает параллельную конструкцию, он создает новую группу потоков, состоящую из себя и некоторого числа дополнительных потоков, и становится главным в новой группе. Все члены новой группы (включая главный поток) выполняют код внутри параллельной конструкции. В конце параллельной конструкции имеется неявный барьер. После параллельной конструкции выполнение пользовательского кода продолжает только главный поток. В параллельный регион могут быть вложены другие параллельные регионы, в которых каждый поток первоначального региона становится основным для своей группы потоков. Вложенные регионы могут в свою очередь включать регионы более глубокого уровня вложенности.

Основной конструкцией стандарта OpenMP для языка программирования C является прагма {\bf parallel}, синтаксис которой приведен в листинге \ref{listing:parallel}.

\mylistingbegin{parallel}{Прагма parallel}
\begin{lstlisting}

#pragma omp parallel \
	if(EXP) \
	num_threads(NUM_THREADS) \
	private(PRIVATE) \
	shared(SHARED)
{

	BODY;

};

\end{lstlisting}
\mylistingend

Блок кода BODY будет выполнен параллельно несколькими вычислительными потоками в том случае, если условие EXP выполняется, иначе блок кода BODY будет выполнен главным вычислительным потоком (потоком с номером 0).

Количество вычислительных потоков можно задать до выполнения прагмы parallel следующими способами:

\begin{itemize}

	\item Оставить по умолчанию.

	По умолчанию количество вычислительных потоков равно количеству процессоров (ядер процессоров), наличествующих в вычислительной системе;

	\item Установить значение переменной окружения OMP\_NUM\_THREADS;

	\item Воспользоваться функцией {\bf omp\_set\_num\_threads()}, прототип которой приведен в листинге \ref{listing:osnt}.

\mylistingbegin{osnt}{Функция omp\_set\_num\_threads()}
\begin{lstlisting}

void omp_set_num_threads(int NUM_THREADS);

\end{lstlisting}
\mylistingend

	Здесь NUM\_THREADS - число вычислительных потоков, выполняющих параллельно содержимое всех последующих прагм parallel;

	\item Указать число вычислительных потоков как значение параметра num\_threads() прагмы parallel.

\end{itemize}

Получить количество вычислительных потоков, которые будут параллельно выполнять содержимое всех последующих прагм parallel, можно, вызвав функцию \linebreak {\bf omp\_get\_max\_threads()}, прототип которой приведен в листинге \ref{listing:ogmt}.

\mylistingbegin{ogmt}{Функция omp\_get\_max\_threads()}
\begin{lstlisting}

int omp_get_max_threads();

\end{lstlisting}
\mylistingend

Наконец, вычислительный поток может получить свой номер с помощью функции \linebreak {\bf omp\_get\_thread\_num()}, прототип которой приведен в листинге \ref{listing:ogtn}.

\mylistingbegin{ogtn}{Функция omp\_get\_thread\_num()}
\begin{lstlisting}

int omp_get_thread_num();

\end{lstlisting}
\mylistingend

Нумерация вычислительных потоков начинается с нуля, при этом нулем маркируется главный вычислительный поток.

Параметры private() и shared() прагмы parallel позволяют настроить процесс разделения памяти вычислительными потоками.

Список имен переменных PRIVATE (имена переменных разделяются запятой) содержит имена тех переменных, которые будут составлять локальные контексты вычислительных потоков - значения этих переменных в одном потоке не будут доступны другим потокам.

Список имен переменных SHARED содержит имена переменных, разделяемых между потоками. Задача программиста состоит в том, чтобы предотвратить различные некорректные ситуации, имеющие место быть при одновременном доступе к какой-либо разделяемой переменной нескольким вычислительными потоками.

Те переменные, имена которых не указаны в списке PRIVATE, считаются разделяемыми.

Параметры if(), num\_threads(), private() и shared() прагмы parallel не являются обязательными и могут быть опущены.

На выходе блока кода BODY процессы с номерами, большими нуля, завершаются - выполнение продолжает только главный вычислительный поток - вычислительный поток с номером 0. При этом главный вычислительный поток на выходе блока кода BODY ожидает завершения всех остальных вычислительных потоков и только после этого продолжает свое выполнение.

Внутри блока кода BODY прагмы parallel допускается использование других прагм стандарта OpenMP (в том числе, и прагмы parallel). Следующие прагмы могут пригодится при выполнении задания к лабораторной работе:

\begin{itemize}

	\item Прагма {\bf single}.

	Синтаксис прагмы single приведен в листинге \ref{listing:single}.

\mylistingbegin{single}{Прагма single}
\begin{lstlisting}

#pragma omp single
{

	BODY;

};

\end{lstlisting}
\mylistingend

	Блок кода BODY будет выполнен только в одном из вычислительных потоков (не обязательно в главном потоке);

	\item Прагма {\bf critical}.

	Синтаксис прагмы critical приведен в листинге \ref{listing:critical}.

\mylistingbegin{critical}{Прагма critical}
\begin{lstlisting}

#pragma omp critical
{

	BODY;

};

\end{lstlisting}
\mylistingend

	Прагма critical ограничивает критические секции кода - в некоторый момент времени только один из вычислительных потоков будет выполнять блок кода BODY;

	\item Прагма {\bf barrier}.

	Синтаксис прагмы barrier приведен в листинге \ref{listing:barrier}.

\mylistingbegin{barrier}{Прагма barrier}
\begin{lstlisting}

#pragma omp barrier

\end{lstlisting}
\mylistingend

	Вычислительный поток, достигнувший прагмы barrier, блокируется до тех пор, пока все остальные вычислительные потоки не достигнут данной прагмы - таким образом достигается синхронизация выполнения вычислительных потоков.

\end{itemize}

\mysubsubsection{Сборка и запуск программ, использующих стандарт OpenMP}

Стандарт OpenMP реализуют большинство современных компиляторов языков программирования C, C++ и Fortran, в числе которых находятся и компиляторы из состава GNU Compiler Collection - GNU C Compiler (gcc), GNU C++ Compiler (g++), GNU Fortran Compiler (gfortran).

Для компиляции программы, написанной на языке программирования C и использующей стандарт OpenMP для организации параллельных вычислений, компилятором GNU C Compiler программист должен:

\begin{itemize}

	\item Включить в программу содержимое заголовочного файла omp.h;
	\item Собрать программу с ключом -fopenmp (передать компилятору ключ -fopenmp в процессе сборки программы).

\end{itemize}

