
\mysubsubsection{Введение}

В настоящее время существуют два принципиально отличных друг от друга аппаратных способа улучшения временной эффективности выполнения произвольных расчетов с помощью средств вычислительной техники.

Первый способ состоит в технологическом совершенствовании средств вычислительной техники. Этот способ, хотя и является относительно дешевым, имеет существенный недостаток - в настоящее время эволюционное развитие технологий создания отдельных узлов вычислительных систем - процессоров, оперативной памяти - подошло к своему теоретическому пределу и требуется революционный скачок, в результате которого человечество должно получить принципиально новые технологии создания перечисленных узлов вычислительных систем. Очевидно, что таковой скачок требует существенных материальных средств, и поэтому его осуществление - дело среднесрочной перспективы.

Второй способ, которому посвящен настоящий курс лабораторных работ, заключается в распределении вычислительной нагрузки между несколькими вычислительными устройствами. Данный способ требует б\'{о}льших, по сравнению с предыдущим способом, затрат на оборудование, однако позволяет практически неограниченно (учитывая, разумеется, материальные и кадровые ресурсы) наращивать вычислительные мощности, могущие быть использованными для решения целевой задачи. В этом случае можно говорить о двух способах повышения временной эффективности выполняемых вычислений:

\begin{itemize}

	\item параллельные вычисления - выполнение различных частей алгоритма в отдельных вычислительных потоках на обособленных друг от друга вычислительных устройствах и дальнейшее мультиплексирование результатов выполнения частей алгоритма главным вычислительным потоком;

	\item распределенные вычисления - выполнение одного и того же алгоритма в отдельных вычислительных потоках на обособленных друг от друга вычислительных устройствах на различных наборах данных. Результаты выполнения алгоритма различными вычислительными потоками объединяются и анализируются главным вычислительным потоком.

\end{itemize}

Вычислительная система, позволяющая выполнять параллельные / распределенные вычисления, состоит из нескольких вычислительных устройств, которые, в свою очередь, состоят, как минимум, из процессора и, возможно, оперативной памяти. В случае, когда вычислительная система представляет собой кластер вычислительных систем, вычислительные устройства суть есть обособленные вычислительные системы с собственным процессором, оперативной памятью, материнской платой, сетевой картой и тому подобными аппаратными средствами.

Существует несколько способов классификации параллельных систем - два наиболее популярных способа приведено ниже:

\begin{itemize}

	\item классификация параллельных систем по Флинну.

	Майкл Флинн (Michael Flynn) в 70-е годы выделил четыре класса архитектур ЭВМ:

	\begin{itemize}
	
		\item ОКОД — вычислительные системы с одиночным потоком команд и одиночным потоком данных (SISD - Single Instruction stream over a Single Data stream);
		\item ОКМД — вычислительные системы с одиночным потоком команд и множественным потоком данных (SIMD - Single Instruction, Multiple Data);
		\item МКОД — вычислительные системы со множественным потоком команд и одиночным потоком данных (MISD - Multiple Instruction Single Data);
		\item МКМД — вычислительные системы со множественным потоком команд и множественным потоком данных (MIMD - Multiple Instruction Multiple Data);

	\end{itemize}

	\item классификация параллельных систем по способу взаимодействия вычислительных потоков:

	\begin{itemize}

		\item взаимодействие через разделяемую память.
		\item взаимодействие путем обмена сообщениями.

	\end{itemize}

\end{itemize}

В настоящей лабораторной работе рассматривается способ организации параллельных вычислений путем запуска нескольких вычислительных потоков, взаимодействующих через разделяемую память. К числу программных библиотек, специализирующихся на организации параллельных вычислений указанным способом, относятся библиотеки, реализующие стандарт OpenMP.

\mysubsubsection{Стандарт OpenMP}

Стандарт OpenMP (Open Multi-Processing) представляет собой набор директив компилятора, процедур и переменных окружения, предназначенных для программирования многопоточных приложений на многопроцессорных системах с общей памятью (SMP-системах).

Первая версия стандарта OpenMP была разработана в 1997 году для языка программирования Fortran. Позже стандарт OpenMP был дополнен спецификациями для языков программирования C и C++. Спецификация стандарта OpenMP может быть бесплатно получена на сайте некоммерческой организации <<OpenMP Architecture Review Board>> \cite{openmp}, курирующей процесс доработки стандарта.

В стандарте OpenMP используется модель параллельного выполнения <<ветвление - слияние>>. Программа OpenMP начинается как единственный поток выполнения, называемый начальным потоком. Когда поток встречает параллельную конструкцию, он создает новую группу потоков, состоящую из себя и некоторого числа дополнительных потоков, и становится главным в новой группе. Все члены новой группы (включая главный поток) выполняют код внутри параллельной конструкции. В конце параллельной конструкции имеется неявный барьер. После параллельной конструкции выполнение пользовательского кода продолжает только главный поток. В параллельный регион могут быть вложены другие параллельные регионы, в которых каждый поток первоначального региона становится основным для своей группы потоков. Вложенные регионы могут в свою очередь включать регионы более глубокого уровня вложенности.

Основной конструкцией стандарта OpenMP для языка программирования C является прагма parallel (листинг \ref{listing:parallel}).

\mylistingbegin{parallel}{Прагма parallel}
\begin{lstlisting}

#pragma omp parallel \
	if(EXP) \
	num_threads(NUM_THREADS) \
	private(PRIVATE) \
	shared(SHARED)
{

	BODY;

};

\end{lstlisting}
\mylistingend

Блок кода BODY будет выполнен параллельно несколькими вычислительными потоками в том случае, если условие EXP выполняется, иначе блок кода BODY будет выполнен главным вычислительным потоком (потоком с номером 0).

Количество вычислительных потоков можно задать до выполнения прагмы parallel следующими способами:

\begin{itemize}

	\item оставить по умолчанию - по умолчанию количество вычислительных потоков равно количеству процессоров (ядер процессоров), наличествующих в вычислительной системе;
	\item установить значение переменной окружения OMP\_NUM\_THREADS;
	\item воспользоваться функцией omp\_set\_num\_threads(), единственный параметр которой суть есть число вычислительных потоков, выполняющих параллельно содержимое всех последующих прагм parallel;
	\item указать число вычислительных потоков как значение параметра num\_threads() прагмы parallel.

\end{itemize}

Получить количество вычислительных потоков, которые будут параллельно выполнять содержимое последующих прагм parallel, можно вызвав функцию omp\_get\_max\_threads(). Вычислительный поток может получить свой номер с помощью функции omp\_get\_thread\_num(). Нумерация вычислительных потоков начинается с нуля, при этом нулем маркируется главный вычислительный поток.

Параметры private() и shared() прагмы parallel позволяют настроить процесс разделения памяти вычислительными потоками.

Список имен переменных PRIVATE (имена переменных разделяются запятой) содержит имена тех переменных, которые будут составлять локальные контексты вычислительных потоков - значения этих переменных в одном потоке не будут доступны другим потокам. Список имен переменных SHARED содержит имена переменных, разделяемых между потоками. Задача программиста состоит в том, чтобы предотвратить различные некорректные ситуации, имеющие место быть при одновременном доступе к какой-либо разделяемой переменной нескольким вычислительными потоками. Те переменные, имена которых не указаны в списке PRIVATE, считаются разделяемыми.

Параметры if(), num\_threads(), private() и shared() не являются обязательными и могут быть опущены.

На выходе блока кода BODY процессы с номерами, большими нуля, завершаются - выполнение продолжает только главный вычислительный поток - вычислительный поток с номером 0. При этом главный вычислительный поток на выходе блока кода BODY ожидает завершения всех остальных вычислительных потоков и только после этого продолжает свое выполнение.

Внутри блока кода BODY прагмы parallel допускается использование других прагм стандарта OpenMP (в том числе, и прагмы parallel). Следующие прагмы (листинг \ref{listing:all-pragma}) могут пригодится при выполнении задания к лабораторной работе:

\begin{itemize}

	\item прагма single - блок кода BODY\_SINGLE будет выполнен только в одном из вычислительных потоков (не обязательно в главном потоке);
	\item прагма critical ограничивает критические секции кода - в некоторый момент времени только один из вычислительных потоков будет выполнять блок кода BODY\_CRITICAL;
	\item прагма barrier - блокирует выполнение вычислительного потока до тех пор, пока все остальные вычислительные потоки не достигнут данной прагмы - таким образом достигается синхронизация выполнения вычислительных потоков.

\end{itemize}

\mylistingbegin{all-pragma}{Вспомогательные прагмы}
\begin{lstlisting}

#pragma omp single { BODY_SINGLE }

#pragma omp critical { BODY_CRITICAL }

#pragma omp barrier

\end{lstlisting}
\mylistingend

\mysubsubsection{Сборка и запуск программ}

Стандарт OpenMP реализуют большинство современных компиляторов языков программирования C, C++ и Fortran, в числе которых находятся и компиляторы из состава GNU Compiler Collection - GNU C Compiler (gcc), GNU C++ Compiler (g++), GNU Fortran Compiler (gfortran).

Для компиляции программы, написанной на языке программирования C и использующей стандарт OpenMP для организации параллельных вычислений, компилятором GNU C Compiler программист должен:

\begin{itemize}

	\item включить в программу содержимое заголовочного файла omp.h;
	\item собрать программу с ключом -fopenmp (передать компилятору ключ -fopenmp в процессе сборки программы).

\end{itemize}

